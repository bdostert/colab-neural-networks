{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdostert/colab-neural-networks/blob/main/RNN_for_words_letter_by_letter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch #Pytorch is a Python module that can create neural networks  and automatically do backpropogation for training a network.\n",
        "import torch.nn as nn #Torch.nn is a submodule of torch that can create various types of networks and functions that operate on them.\n",
        "\n",
        "\n",
        "# single-direction RNN, optionally tied embeddings\n",
        "class Emb_RNN(nn.Module):\n",
        "    def __init__(self, params, use_LSTM=False):\n",
        "        super(Emb_RNN, self).__init__()\n",
        "        self.d_embs = params['d_emb'] #dimension of embeddings\n",
        "        self.d_hid =  params['d_hid'] #dimension of hidden layer\n",
        "        self.embeddings= nn.Embedding(params['num_chs'], self.d_embs) #A separate embeddding for each character in char list\n",
        "        self.use_LSTM = use_LSTM #LSTM is more powerful than a simple RNN\n",
        "        # input to recurrent layer, default nonlinearity is tanh\n",
        "        if use_LSTM:\n",
        "            self.i2R = nn.LSTMCell(self.d_embs, self.d_hid)\n",
        "        else:\n",
        "            self.i2R = nn.RNNCell(self.d_embs, self.d_hid)\n",
        "        # recurrent to output layer\n",
        "        self.R2o = nn.Linear(self.d_hid, params['num_chs'])\n",
        "        if self.d_embs == self.d_hid:\n",
        "            self.R2o.weight = self.embeddings.weight\n",
        "\n",
        "\n",
        "    def forward(self, ch_indices):\n",
        "        preds = [] #initialize list of predictions, each of which is a score for each character\n",
        "        for j, ch_ix in enumerate(ch_indices):\n",
        "            emb = self.embeddings(ch_ix) #Get the embedding of the character\n",
        "            emb = torch.unsqueeze(emb, 0)\n",
        "            if self.use_LSTM:\n",
        "                if j == 0:\n",
        "                    hidden, context = self.i2R(emb) #We don't supply the hidden or context the first time.\n",
        "                                                     #Pytorch will default it to zeroes.\n",
        "                else:\n",
        "                    hidden, context = self.i2R(emb, (hidden, context))\n",
        "            else:\n",
        "                if j == 0:\n",
        "                    hidden = self.i2R(emb)\n",
        "                else:\n",
        "                    hidden = self.i2R(emb, hidden)\n",
        "            preds.append(self.R2o(hidden))\n",
        "        return torch.stack(preds, dim=1) #The predictions of the characters are stacked into one matrix. Each row is a prediction set.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3Y6PkBlQMrnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyLeDXpxL51N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import re\n",
        "import sys\n",
        "import collections\n",
        "import os\n",
        "import random\n",
        "\n",
        "verbose = False\n",
        "play = True\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "d_emb = 64 #Hyperparameters can be changed here.\n",
        "n_layers = 1\n",
        "d_hid = 64\n",
        "lr = 0.003\n",
        "use_LSTM = True\n",
        "if use_LSTM:\n",
        "    model_type = 'lstm'\n",
        "else:\n",
        "    model_type = 'rnn'\n",
        "\n",
        "\n",
        "def train(net, words, params):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimiser = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    if os.path.exists(params['save_path']):\n",
        "        checkpoint = torch.load(params['save_path'])\n",
        "        print('Loading checkpoint')\n",
        "        net.load_state_dict(checkpoint['net_state_dict'])\n",
        "        optimiser.load_state_dict(checkpoint['optimiser_state_dict'])\n",
        "        net.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        ep_loss = 0.\n",
        "        num_tested = 0\n",
        "        num_correct = 0\n",
        "        your_epoch_score = 0\n",
        "        your_epoch_score2 = 0\n",
        "        model_epoch_score = 0\n",
        "        for counter, i in enumerate(torch.randperm(len(words))): #Randonly choose a word.\n",
        "            pred = net(words[i]) #Predict on the model.\n",
        "            pred = pred[:,:-1,:].contiguous().view(-1, pred.size(-1)) #Offset the predictions from the target\n",
        "                    #so that we predict the next character based on the previous character.\n",
        "            target = words[i][1:]\n",
        "            target = target.contiguous().view(-1)\n",
        "            target = target.long()\n",
        "            #print('pt', pred.size(), target.size())\n",
        "            with torch.no_grad():\n",
        "                pred_numpy = np.argmax(pred.numpy(), axis=1).tolist()\n",
        "                target_numpy = target.numpy().tolist()\n",
        "                matched_chars = [c1 for c1, c2 in zip(pred_numpy, target_numpy) if c1 == c2]\n",
        "                num_tested += len(target_numpy)\n",
        "                num_correct += len(matched_chars)\n",
        "                if play and counter != 0 and counter % 1000 == 0:\n",
        "                    your_score = 0\n",
        "                    your_score2 = 0\n",
        "                    model_score = 0\n",
        "                    print('Player 1\\'s score so far for this epoch', your_epoch_score)\n",
        "                    print('Player 2\\'s score so far for this epoch', your_epoch_score2)\n",
        "                    print('The model\\'s score so far for this epoch', model_epoch_score)\n",
        "                    #print(''.join([ix2ch[str(c)] for c in pred_numpy]), ''.join([ix2ch[str(c)] for c in target_numpy]))\n",
        "                    for k in range(2, len(target_numpy)):\n",
        "                        #print(''.join([ix2ch[str(c)] for c in target_numpy[:k]]), ''.join([ix2ch[str(c)] for c in target_numpy[:k]])+ix2ch[str(pred_numpy[k])])\n",
        "                        print('Player 1 guess the continuation of', ''.join([ix2ch[str(c)] for c in target_numpy[:k-1]]), 'and press Enter')\n",
        "                        guess = input()\n",
        "                        print('Player 1 guessed', guess, 'The model guessed', ''.join([ix2ch[str(c)] for c in pred_numpy[:k-1]])+ix2ch[str(pred_numpy[k])])\n",
        "                        print('Player 2 guess the continuation of', ''.join([ix2ch[str(c)] for c in target_numpy[:k-1]]), 'and press Enter')\n",
        "                        guess2 = input()\n",
        "                        print('Player 2 guessed', guess2, 'The model guessed', ''.join([ix2ch[str(c)] for c in pred_numpy[:k-1]])+ix2ch[str(pred_numpy[k])])\n",
        "                        print('The actual target is', ''.join([ix2ch[str(c)] for c in target_numpy[:k]]))\n",
        "                        if guess == ''.join([ix2ch[str(c)] for c in target_numpy[:k]]):\n",
        "                            your_score += 1\n",
        "                            your_epoch_score += 1\n",
        "                        if guess2 == ''.join([ix2ch[str(c)] for c in target_numpy[:k]]):\n",
        "                            your_score2 += 1\n",
        "                            your_epoch_score2 += 1\n",
        "                        if ''.join([ix2ch[str(c)] for c in target_numpy[:k-1]])+ix2ch[str(pred_numpy[k])] == ''.join([ix2ch[str(c)] for c in target_numpy[:k]]):\n",
        "                            model_score += 1\n",
        "                            model_epoch_score += 1\n",
        "                        print('Player 1\\'s score:', your_score, '\\nPlayer 2\\'s score:', your_score2, '\\nModel score:', model_score)\n",
        "                    print()\n",
        "                else:\n",
        "                    if counter % 1000 == 0:\n",
        "                        print('Trained on', counter, 'words so far in this epoch')\n",
        "            loss = criterion(pred, target)\n",
        "            if torch.isnan(loss):\n",
        "                with torch.no_grad():\n",
        "                    print(pred, target, words[i], ix2ch[i])\n",
        "                    exit()\n",
        "            loss.backward()\n",
        "            optimiser.step()\n",
        "            optimiser.zero_grad()\n",
        "            ep_loss += loss.detach()\n",
        "        print('Epoch', epoch, 'Accuracy', round(num_correct / num_tested, 4), 'Loss', ep_loss)\n",
        "        print('Saving checkpoint')\n",
        "        torch.save({'net_state_dict': net.state_dict(),  'optimiser_state_dict': optimiser.state_dict()}, params['save_path'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "words = collections.defaultdict(lambda: [])\n",
        "words_as_indices = {}\n",
        "models = {} #Put the models in a dictionary in case we train on multiple models for multiple datasets.\n",
        "path = '' #No directory needs to be specified if the files are uploaded here.\n",
        "#word_files = ['english']\n",
        "word_files = ['ukwords.txt']\n",
        "input('Make sure that the data files are uploaded to Colab for this session \\nand then press Enter to continue.')\n",
        "for word_file in word_files:\n",
        "    chars = []\n",
        "    print(path+word_file)\n",
        "    if os.path.isfile(path+word_file):\n",
        "        print('Processing file', word_file)\n",
        "        with open(path+word_file, 'r') as f0:\n",
        "            for i, line in enumerate(f0.readlines()):\n",
        "                if i % 1000 == 0:\n",
        "                    print('Processed', i, 'lines.')\n",
        "                line = line.rstrip()\n",
        "                line = '#' + line + '#'\n",
        "                if len(line) < 4:\n",
        "                    continue\n",
        "                words[word_file].append(line)\n",
        "                for ch in line:\n",
        "                     if ch not in chars:\n",
        "                         chars.append(ch.lower())\n",
        "    else:\n",
        "        print('No file found with  name', word_file)\n",
        "        exit()\n",
        "\n",
        "    ch2ix = {}\n",
        "    ix2ch = {}\n",
        "    total_chars = len(chars)\n",
        "    print('total chars', total_chars)\n",
        "    for i, char in enumerate(chars):\n",
        "        ch2ix[char] = i #Set up dictionaries for converting characters to indices and vice versa.\n",
        "        ix2ch[str(i)] = char\n",
        "    with open(word_file+'.ch2ix.json', 'w') as f1:\n",
        "        json.dump(ch2ix, f1)\n",
        "    with open(word_file+'.ix2ch.json', 'w') as f2:\n",
        "        json.dump(ix2ch, f2)\n",
        "    words_as_indices[word_file] = [torch.LongTensor([ch2ix[c] for c in word])\n",
        "        for word in words[word_file]\n",
        "      ]\n",
        "\n",
        "    params = {'num_chs': total_chars,\n",
        "              'd_emb': d_emb,\n",
        "              'num_layers': n_layers,\n",
        "              'd_hid': d_hid,\n",
        "              'lr': lr,\n",
        "              'epochs': num_epochs,\n",
        "              'save_path': word_file+'.'+model_type+'.d_emb'+str(d_emb)+'.n_layers'+str(n_layers)+'.d_hid'+str(d_hid)+'.lr'+str(lr)+'.pth'}\n",
        "\n",
        "\n",
        "    models[word_file] = Emb_RNN(params, use_LSTM)\n",
        "    train(models[word_file], words_as_indices[word_file], params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GETnl7KZMOhJ",
        "outputId": "6f3db915-c634-4c89-f734-67fb9a7beaaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Make sure that the data files are uploaded to Colab for this session \n",
            "and then press Enter to continue.\n",
            "ukwords.txt\n",
            "Processing file ukwords.txt\n",
            "Processed 0 lines.\n",
            "Processed 1000 lines.\n",
            "Processed 2000 lines.\n",
            "Processed 3000 lines.\n",
            "Processed 4000 lines.\n",
            "Processed 5000 lines.\n",
            "Processed 6000 lines.\n",
            "Processed 7000 lines.\n",
            "Processed 8000 lines.\n",
            "Processed 9000 lines.\n",
            "Processed 10000 lines.\n",
            "Processed 11000 lines.\n",
            "Processed 12000 lines.\n",
            "total chars 27\n",
            "Loading checkpoint\n",
            "Trained on 0 words so far in this epoch\n",
            "Player 1's score so far for this epoch 0\n",
            "Player 2's score so far for this epoch 0\n",
            "The model's score so far for this epoch 0\n",
            "Player 1 guess the continuation of s and press Enter\n",
            "st\n",
            "Player 1 guessed st The model guessed sr\n",
            "Player 2 guess the continuation of s and press Enter\n",
            "sa\n",
            "Player 2 guessed sa The model guessed sr\n",
            "The actual target is st\n",
            "Player 1's score: 1 \n",
            "Player 2's score: 0 \n",
            "Model score: 0\n",
            "Player 1 guess the continuation of st and press Enter\n",
            "str\n",
            "Player 1 guessed str The model guessed sta\n",
            "Player 2 guess the continuation of st and press Enter\n",
            "sta\n",
            "Player 2 guessed sta The model guessed sta\n",
            "The actual target is str\n",
            "Player 1's score: 2 \n",
            "Player 2's score: 0 \n",
            "Model score: 0\n",
            "Player 1 guess the continuation of str and press Enter\n",
            "stra\n",
            "Player 1 guessed stra The model guessed strn\n",
            "Player 2 guess the continuation of str and press Enter\n",
            "stri\n",
            "Player 2 guessed stri The model guessed strn\n",
            "The actual target is stra\n",
            "Player 1's score: 3 \n",
            "Player 2's score: 0 \n",
            "Model score: 0\n",
            "Player 1 guess the continuation of stra and press Enter\n",
            "strai\n",
            "Player 1 guessed strai The model guessed strag\n",
            "Player 2 guess the continuation of stra and press Enter\n",
            "strap\n",
            "Player 2 guessed strap The model guessed strag\n",
            "The actual target is stran\n",
            "Player 1's score: 3 \n",
            "Player 2's score: 0 \n",
            "Model score: 0\n",
            "Player 1 guess the continuation of stran and press Enter\n",
            "strang\n",
            "Player 1 guessed strang The model guessed stran#\n",
            "Player 2 guess the continuation of stran and press Enter\n",
            "strang\n",
            "Player 2 guessed strang The model guessed stran#\n",
            "The actual target is strang\n",
            "Player 1's score: 4 \n",
            "Player 2's score: 1 \n",
            "Model score: 0\n",
            "Player 1 guess the continuation of strang and press Enter\n",
            "strange\n",
            "Player 1 guessed strange The model guessed strangr\n",
            "Player 2 guess the continuation of strang and press Enter\n",
            "strange\n",
            "Player 2 guessed strange The model guessed strangr\n",
            "The actual target is strange\n",
            "Player 1's score: 5 \n",
            "Player 2's score: 2 \n",
            "Model score: 0\n",
            "Player 1 guess the continuation of strange and press Enter\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-db64e439ef24>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_file\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmb_RNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_LSTM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_as_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-4f442bebfe29>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, words, params)\u001b[0m\n\u001b[1;32m     66\u001b[0m                         \u001b[0;31m#print(''.join([ix2ch[str(c)] for c in target_numpy[:k]]), ''.join([ix2ch[str(c)] for c in target_numpy[:k]])+ix2ch[str(pred_numpy[k])])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Player 1 guess the continuation of'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix2ch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_numpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'and press Enter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                         \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Player 1 guessed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The model guessed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix2ch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_numpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mix2ch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_numpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Player 2 guess the continuation of'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix2ch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_numpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'and press Enter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}