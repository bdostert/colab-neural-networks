{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsokuq0a0z3C"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "lr = 0.003\n",
        "wdlen = 6\n",
        "lang_list = ['uk', 'la','it']\n",
        "\n",
        "class PredictLanguage(nn.Module):\n",
        "    def __init__(self, lang_list):\n",
        "        super(PredictLanguage, self).__init__()\n",
        "        self.num_to_train = 23000\n",
        "        self.lang_list = lang_list\n",
        "        self.lang2ix = {key: i for (i, key) in enumerate(self.lang_list)}\n",
        "\n",
        "    def create_wordlists(self):\n",
        "        self.wordlist_dict = collections.defaultdict(lambda: [])\n",
        "        for lang in self.lang_list:\n",
        "            if os.path.isfile(lang+'_len'+str(wdlen)+'.txt'):\n",
        "                with open(lang+'_len'+str(wdlen)+'.txt') as f0:\n",
        "                    for wd in f0.readlines():\n",
        "                        wd = wd.rstrip()\n",
        "                        #print(wd)\n",
        "                        self.wordlist_dict[lang].append(wd.lower())\n",
        "                print('Wordlist of words of length', wdlen, 'successfully created for language', lang)\n",
        "            else:\n",
        "                print('Language', lang, 'with path', lang+'_len'+str(wdlen)+'.txt', 'not found!')\n",
        "\n",
        "    def get_phoneme_list(self):\n",
        "        self.phonemes = []\n",
        "        for lang in list(self.wordlist_dict):\n",
        "            for wd in self.wordlist_dict[lang]:\n",
        "                for phoneme in wd:\n",
        "                    if phoneme not in self.phonemes:\n",
        "                        self.phonemes.append(phoneme)\n",
        "        print('There are', len(self.phonemes), 'phonemes across the', len(lang_list), 'languages')\n",
        "        self.phoneme2ix = {}\n",
        "        for i, phoneme in enumerate(self.phonemes):\n",
        "            self.phoneme2ix[phoneme] = torch.tensor(i)\n",
        "\n",
        "    def create_embeddings_for_phonemes(self):\n",
        "        self.phoneme_embeddings = nn.Embedding(len(self.phonemes),len(self.phonemes))\n",
        "\n",
        "    def set_up_model(self):\n",
        "        self.dim_hid1 = 32\n",
        "        self.dim_hid2 = 32\n",
        "        self.input2hidden1 = nn.Linear(len(self.phonemes)*wdlen, self.dim_hid1)\n",
        "        self.hidden1hidden2 = nn.Linear(self.dim_hid1, self.dim_hid2)\n",
        "        self.hidden2output = nn.Linear(self.dim_hid2, len(lang_list))\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, input_word):\n",
        "        phoneme_vectors = []\n",
        "        for phoneme in input_word:\n",
        "            phoneme_vectors.append(self.phoneme_embeddings(self.phoneme2ix[phoneme]))\n",
        "        vector_for_word = torch.unsqueeze(torch.cat(phoneme_vectors, dim=0), 0)\n",
        "        #print('vfw', vector_for_word.size())\n",
        "        hid1 = self.input2hidden1(vector_for_word)\n",
        "        hid1 = self.sigmoid(hid1)\n",
        "        hid2 = self.hidden1hidden2(hid1)\n",
        "        hid2 = self.sigmoid(hid2)\n",
        "        return self.hidden2output(hid2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(model):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimiser = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    num_tested = 0\n",
        "    num_correct = 0\n",
        "    ep_loss = 0\n",
        "    #print('ll', model.lang_list)\n",
        "    for i in range(model.num_to_train):\n",
        "        lang = random.choice(lang_list)\n",
        "        #print('lang', lang)\n",
        "        #print(model.wordlist_dict[lang])\n",
        "        wd = random.choice(model.wordlist_dict[lang])\n",
        "        #print(lang, wd)\n",
        "        num_tested += 1\n",
        "        pred = model(wd)\n",
        "        #print('pli', pred)\n",
        "        target_lang_ix = model.lang2ix[lang]\n",
        "        target = torch.unsqueeze(torch.tensor(target_lang_ix), 0)\n",
        "        with torch.no_grad():\n",
        "            pred_numpy = np.argmax(pred.numpy(), axis=1).tolist()[0]\n",
        "            if pred_numpy == target_lang_ix:\n",
        "                num_correct += 1\n",
        "        loss = criterion(pred, target)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "        optimiser.zero_grad()\n",
        "        ep_loss += loss.detach()\n",
        "        if i % 1000 == 0 and i >0:\n",
        "            average_loss = ep_loss / 1000\n",
        "            ep_loss = 0\n",
        "            print(i, average_loss, 'training accuracy on last 1000 examples', round(num_correct / num_tested, 4))\n",
        "            num_tested = 0\n",
        "            num_correct = 0"
      ],
      "metadata": {
        "id": "eDNR3yDNr-c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PredictLanguage(lang_list)\n",
        "model.create_wordlists()\n",
        "model.get_phoneme_list()\n",
        "model.create_embeddings_for_phonemes()\n",
        "model.set_up_model()\n",
        "train(model)\n",
        "\n",
        "\n",
        "#with torch.no_grad():\n",
        "#    embeddings = model.phoneme_embeddings.weight.numpy()\n",
        "#    #print(embeddings)\n",
        "#    print(embeddings.shape)\n",
        "#    labels = model.phonemes\n",
        "\n",
        "#/Y = tsne(embeddings, 2, 50, 5.0)\n"
      ],
      "metadata": {
        "id": "1VIH3kYArmpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37cc4f49-4f3a-4a4d-f440-2fc5856c4e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wordlist of words of length 6 successfully created for language uk\n",
            "Wordlist of words of length 6 successfully created for language la\n",
            "Wordlist of words of length 6 successfully created for language it\n",
            "There are 26 phonemes across the 3 languages\n",
            "1000 tensor(0.7661) training accuracy on last 1000 examples 0.6593\n",
            "2000 tensor(0.5166) training accuracy on last 1000 examples 0.806\n",
            "3000 tensor(0.5304) training accuracy on last 1000 examples 0.787\n",
            "4000 tensor(0.4585) training accuracy on last 1000 examples 0.836\n",
            "5000 tensor(0.4691) training accuracy on last 1000 examples 0.822\n",
            "6000 tensor(0.4481) training accuracy on last 1000 examples 0.822\n",
            "7000 tensor(0.3993) training accuracy on last 1000 examples 0.845\n",
            "8000 tensor(0.4116) training accuracy on last 1000 examples 0.84\n",
            "9000 tensor(0.3473) training accuracy on last 1000 examples 0.864\n",
            "10000 tensor(0.3432) training accuracy on last 1000 examples 0.869\n",
            "11000 tensor(0.3631) training accuracy on last 1000 examples 0.851\n",
            "12000 tensor(0.3413) training accuracy on last 1000 examples 0.877\n",
            "13000 tensor(0.3142) training accuracy on last 1000 examples 0.882\n",
            "14000 tensor(0.3060) training accuracy on last 1000 examples 0.884\n",
            "15000 tensor(0.3101) training accuracy on last 1000 examples 0.879\n",
            "16000 tensor(0.2873) training accuracy on last 1000 examples 0.903\n",
            "17000 tensor(0.2845) training accuracy on last 1000 examples 0.902\n",
            "18000 tensor(0.2491) training accuracy on last 1000 examples 0.909\n",
            "19000 tensor(0.2669) training accuracy on last 1000 examples 0.897\n",
            "20000 tensor(0.2782) training accuracy on last 1000 examples 0.895\n",
            "21000 tensor(0.2379) training accuracy on last 1000 examples 0.908\n",
            "22000 tensor(0.2324) training accuracy on last 1000 examples 0.914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "while True:\n",
        "    test_wd = input('Type a word of '+str(wdlen)+' letters to see what language the model predicts for it.\\n')\n",
        "    if len(test_wd) != wdlen:\n",
        "        print('Your word does not have', wdlen, 'letters!')\n",
        "    else:\n",
        "        break\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred = model(test_wd.lower())\n",
        "    pred_numpy = np.argmax(pred.numpy(), axis=1).tolist()[0]\n",
        "    print('Prediction is', lang_list[pred_numpy])"
      ],
      "metadata": {
        "id": "eGaHOgnhjbNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b6e08f-c256-4d8c-abf7-1310948dcbe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type a word of 6 letters to see what language the model predicts for it.\n",
            "canine\n",
            "Prediction is it\n"
          ]
        }
      ]
    }
  ]
}